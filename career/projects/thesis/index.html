<!DOCTYPE HTML>
<html>
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<title>Master thesis NeuralVisUAL - Jannik Hofmann</title>
	<link rel="stylesheet" href="/build/styles.css">
	<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
	<script> 
		$(function(){
		  $("#header").load("/src/header.html"); 
		});
		$(function(){
		  $("#footer").load("/src/footer.html"); 
		});
	</script>
</head>
<body class="text-textc" lang="en">
	<div class=""> <!-- md:grid md:grid-cols-3 content wrapper -->
		<div id="header"></div>

		<header class="-mt-3">
			<a class="" href=".." title="See list of projects"><div class="backlink inline !text-[rgba(0,0,0,0.7)] !hover:text-black hover:opacity-100 border-b-0 bg-white !hover:bg-black 
			!bg-opacity:100"><svg xmlns="http://www.w3.org/2000/svg" class="h-5 w-5 inline -mt-1" fill="none" viewBox="0 0 24 24" stroke="currentColor">
				<path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 19l-7-7m0 0l7-7m-7 7h18" />
			  </svg>&ensp;list of projects</div></a>
			<!-- <div class="md:hidden -mt-4 bg-white max-h-[calc(100vh-5rem)] overflow-hidden pt-3 relative h-[calc(100vw/1080*1442+2.5rem)] md:h-[calc(100vw/16*9+3.5rem)]"> -->
				<!-- <script src="https://cdn.jsdelivr.net/gh/dixonandmoe/rellax@master/rellax.min.js"></script>
				<script>
					// Accepts any class name
					var rellax = new Rellax('.rellax');
				</script> -->

				<!-- <div class="absolute overflow-hidden bottom-0 top-0 mt-16 left-0 right-0">
					<div class="md:hidden absolute bottom-0 top-0 left-0 right-0 bg-cover blur-lg brightness-90 contrast-75 bg-center bg-no-repeat shadow-inner-lg-up" style="background-image: url('/img/wanderung.png'); background-origin: content-box;"></div>
					<div class="md:hidden absolute bottom-0 top-0 left-0 right-0 bg-contain bg-center bg-no-repeat shadow-inner-lg-up" style="background-image: url('/img/wanderung.png'); background-origin: content-box;"></div>

					<div class="hidden md:block absolute bottom-0 top-0 left-0 right-0 bg-cover blur-lg brightness-90 contrast-75 bg-center bg-no-repeat shadow-inner-lg-up" style="background-image: url('/img/wanderung2.png'); background-origin: content-box;"></div>
					<div class="hidden md:block absolute bottom-0 top-0 left-0 right-0 bg-contain bg-center bg-no-repeat shadow-inner-lg-up" style="background-image: url('/img/wanderung2.png'); background-origin: content-box;"></div>
					< !-- <div class="bg-gradient-to-b from-transparent to-[#00000077] opacity-100 hover:opacity-100 w-full h-full"></div> -- >
				</div> -->
				<!-- <img class="z-20 rounded-full shadow-xl w-48 -mr-24 absolute bottom-1/2 right-1/2 sm:bottom-32 sm:mr-auto right-sm-mainpaddingx md:bottom-20 lg:right-1/3 md:w-72 lg:-mr-36" src="/img/profilepic1.png"> -->
				
				<!-- <h3 class="text-2xl font-semibold"></h3> -->
			<!-- </div> -->
		</header>
		<main class="mainarea bg-slate-200 !min-h-0 pb-6 text-justify relative">
			<div class="-mt-4">
				<div class="posterdiv"><img class="max-h-[calc(max(100vh-4rem,100vh*0.8))] max-w-full object-contain shadow-xl" src="/img/master thesis title page.jpg"></div>

				<div class="mb-8 mt-12 break-word"><span class="text-left"><h2 class="pagetitle !font-normal !mb-0 !text-uni-800 space">master thesis <span class="deactivated-md-hidden"><br /></span><span class="italic small-caps font-bold">Neu&shy;ral&shy;Vis&shy;U&shy;AL</span></h2><br /><h3 class="font-bold mt-0 text-2xl text-uni-700">Deep neural network visualization in the Unreal Engine for interactive fly-through exploration</h3><br />
				<h4 class="font-thin text-xl">An open-source, extensible and modular framework for visualizing inner workings of artifical intelligence, developed as my master thesis for graduation in Media Computer Science at the University of TÃ¼bingen.</h4></span></div>
				<div class="mdd:grid-cols-[53%_auto] mdd:grid mdd:gap-12 clear-both">
					<div class="mdd:col-start-2 mdd:col-end-3 mdd:order-2">
						<a target="_blank" href="https://github.com/cgtuebingen/jannik-hofmann-master-thesis" title="View the open-source code of this project on github" class="no-underline"><div class="button mx-auto !my-6 !mt-0 w-auto bg-[#333333] text-[#f5f5f5] !shadow-lg hover:!shadow-xl active:!shadow-xl">
							<svg xmlns="http://www.w3.org/2000/svg" class="h-5 w-5 inline-block" aria-hidden="true" role="img" width="1.03em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 250"><path fill="currentColor" d="M128.001 0C57.317 0 0 57.307 0 128.001c0 56.554 36.676 104.535 87.535 121.46c6.397 1.185 8.746-2.777 8.746-6.158c0-3.052-.12-13.135-.174-23.83c-35.61 7.742-43.124-15.103-43.124-15.103c-5.823-14.795-14.213-18.73-14.213-18.73c-11.613-7.944.876-7.78.876-7.78c12.853.902 19.621 13.19 19.621 13.19c11.417 19.568 29.945 13.911 37.249 10.64c1.149-8.272 4.466-13.92 8.127-17.116c-28.431-3.236-58.318-14.212-58.318-63.258c0-13.975 5-25.394 13.188-34.358c-1.329-3.224-5.71-16.242 1.24-33.874c0 0 10.749-3.44 35.21 13.121c10.21-2.836 21.16-4.258 32.038-4.307c10.878.049 21.837 1.47 32.066 4.307c24.431-16.56 35.165-13.12 35.165-13.12c6.967 17.63 2.584 30.65 1.255 33.873c8.207 8.964 13.173 20.383 13.173 34.358c0 49.163-29.944 59.988-58.447 63.157c4.591 3.972 8.682 11.762 8.682 23.704c0 17.126-.148 30.91-.148 35.126c0 3.407 2.304 7.398 8.792 6.14C219.37 232.5 256 184.537 256 128.002C256 57.307 198.691 0 128.001 0Zm-80.06 182.34c-.282.636-1.283.827-2.194.39c-.929-.417-1.45-1.284-1.15-1.922c.276-.655 1.279-.838 2.205-.399c.93.418 1.46 1.293 1.139 1.931Zm6.296 5.618c-.61.566-1.804.303-2.614-.591c-.837-.892-.994-2.086-.375-2.66c.63-.566 1.787-.301 2.626.591c.838.903 1 2.088.363 2.66Zm4.32 7.188c-.785.545-2.067.034-2.86-1.104c-.784-1.138-.784-2.503.017-3.05c.795-.547 2.058-.055 2.861 1.075c.782 1.157.782 2.522-.019 3.08Zm7.304 8.325c-.701.774-2.196.566-3.29-.49c-1.119-1.032-1.43-2.496-.726-3.27c.71-.776 2.213-.558 3.315.49c1.11 1.03 1.45 2.505.701 3.27Zm9.442 2.81c-.31 1.003-1.75 1.459-3.199 1.033c-1.448-.439-2.395-1.613-2.103-2.626c.301-1.01 1.747-1.484 3.207-1.028c1.446.436 2.396 1.602 2.095 2.622Zm10.744 1.193c.036 1.055-1.193 1.93-2.715 1.95c-1.53.034-2.769-.82-2.786-1.86c0-1.065 1.202-1.932 2.733-1.958c1.522-.03 2.768.818 2.768 1.868Zm10.555-.405c.182 1.03-.875 2.088-2.387 2.37c-1.485.271-2.861-.365-3.05-1.386c-.184-1.056.893-2.114 2.376-2.387c1.514-.263 2.868.356 3.061 1.403Z"/></svg>
							&thinsp;
							<span class="">View the open-source repository on github</span>
						</div></a>
						<a target="_blank" href="https://drive.google.com/file/d/1lViMtYSkV5p2BQoxMivBG5NKNootr9Fz/view?usp=sharing" title="View the complete master thesis as a PDF file" class="no-underline"><div class="button mx-auto !my-6 w-auto bg-uni-500 text-[#f5f5f5] !shadow-lg hover:!shadow-xl active:!shadow-xl">
							<svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6 inline-block" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2">
								<path stroke-linecap="round" stroke-linejoin="round" d="M4 16v1a3 3 0 003 3h10a3 3 0 003-3v-1m-4-4l-4 4m0 0l-4-4m4 4V4" />
							</svg>
							&thinsp;
							<span class="">Download the thesis as PDF</span>
						</div></a>
						<div class="prose max-w-none !break-words">
							<h4 class="">Time frame</h4><p>Mar 2021 - Sep 2021, full-time</p>
							<h4 class="">Thesis content</h4><p>A total of 106 pages, citing 211 different sources, featuring an extensive background section that explains Deep Neural Networks, AI visualizations, and force-based graph drawing algorithms in a detailed manner.</p>
							<h4 class="">Open-source license</h4><p>The code of this master thesis project is published under the open-source license GNU GPLv3.</p>
							<h4 class="">Professors / supervision</h4><p>Examining professor: <span class="italic">Prof. Dr. Hendrik Lensch</span>,<br />secondary professor: <span class="italic">Prof. Dr. Martin V. Butz</span>,<br />project supervision: <span class="italic">Mark Boss</span></p>
							<h4 class="">Final grade</h4><p>For thesis and defense each 1.0 <span class="italic text-smm">(equivalent to American A / GPA 4.0)</span></p>
							<h4 class="">Tools utilized</h4><p class="font-mono">Unreal Engine, Python, Numpy, Blueprints, C++, Tensorflow, Keras, Websocket, Trello, LaTeX, Git</p>
							<h4 class="">Skills I learned / improved upon through this project</h4><p	>Project management, development prioritisation, framework building, interactive visualizations, Artificial Intelligence, Deep Neural Networks, Force-based layouting, building asynchronous server-client infrastructure</p>
						</div>
					</div>

					<div class="mdd:col-start-1 mdd:col-end-2 mdd:order-1">
						<div class="prose max-w-none">
							<details open>
								<summary class="cursor-pointer"><h4 class="inline-block">Abstract</h4></summary>
								<p>Deep neural networks have astounding capabilities, surpassing human abilities in many disciplines. Due to their increasingly complex nature, with modern architectures consisting of hundreds of millions, sometimes even billions of trainable weights, it is virtually impossible for researchers to intuitively understand how exactly these networks come to produce such incredible results. Research in neural network interpretability and network visualization aims to provide more insight into the inner workings of artificial intelligence.</p>
								<p>NeuralVisUAL (Deep <span class="font-bold">Neural</span> Network <span class="font-bold">Vis</span>ualization in the <span class="font-bold">U</span>nreal Engine for Inter<span class="font-bold">a</span>ctive F<span class="font-bold">l</span>y-through Exploration) is the first step towards an extensible framework for neural network visualization, facilitating a better understanding of these networks through exploration. It is a modular open-source application, written in python, C++, and Unreal Engine blueprints, that visualizes any feed-forward deep neural network developed in TensorFlow and Keras. NeuralVisUAL utilizes the force-based algorithm ForceAtlas 2 with some modifications to calculate a meaningful layout of the given network on a two-dimensional plane. This layout determines where to spawn objects in a virtual game environment, which the user can freely explore, interacting with the network through this application. Furthermore, the application visualizes the kernels of convolution layers in convoluational neural networks, the corresponding activation maps, saliency maps, and integrated gradients according to user-defined preferences.</p>
								<p>NeuralVisUAL consists of several distinct modules connected by precisely defined interface interactions. Among other advantages, this allows for a separation between a server interacting with the neural network and an Unreal Engine 4 client that renders the visualization for the user to explore freely.</p>
							</details>
							
							<details>
								<summary class="cursor-pointer"><h4 class="inline-block">Conclusion</h4></summary>
								<p>This thesis presents NeuralVisUAL, a modular open-source application designated to visualizing feed-forward DNNs using UE4 [Inc21]. It utilizes a modified FBA based on ForceAtlas 2 [JVHB14] to calculate an easily comprehensible 2D layout that aims to visualize the directional information flow, keeping connected layers close while maintaining space between unrelated ones. After calculating and rendering this layout in the virtual environment, the application can visualize convolution kernels, activation maps, saliency maps, and integrated gradients within the network.</p>
								<p>NeuralVisUAL contains several distinct modules connected by well-defined interfaces. Most crucial is the separation between server and client, which allows the visualization to run on a different machine than the neural network to be analyzed. The python server directly loads the neural network, interacts with it, and processes its data. Furthermore, it is responsible for calculating visualizations from this obtained data, according to visualization settings that the user can adapt to each project. To render these visualizations, it generates instructions for manipulating the virtual world and sends them to the client via a WebSocket connection [FM11], serialized with msgpack [Fur19]. Within the NeuralVisUAL's client module, a UE4 C++ plugin receives these instructions and calls blueprint functions [Inc20b] during this unpacking process. These methods, designed in Unreal's blueprint visual scripting system [Inc20b], are responsible for caching the relevant data from unpacking, interpreting the instructions, and spawning objects in the virtual world. Finally, UE4 renders this world, providing an interactive game rendering environment and allowing the user to freely explore the visualization as a 3D representation [Inc21]. The user exclusively interacts with the neural network through this application and can send commands to the server through a custom console within the game environment. The client relays those commands back through blueprints, the C++ plugin, and the WebSocket connection to the server. The python server finally asynchronously receives and processes these commands, calling the corresponding methods to fulfill the user's wishes, such as requests for new visualizations.</p>
								<p>This modularity provides several key advantages. It relieves development efforts due to circumventing relatively long C++ compilation times, yet still providing a high performance for computationally expensive calculations, especially when the server runs on a high-performance machine. Furthermore, the separation between server and client facilitates analyzing networks on servers dedicated to ML research while executing the UE4 rendering application on a client machine. Finally, this modularity permits quick adaptation of NeuralVisUAL to other use cases, extending its functionality or even modifying modules to work for completely different use cases.</p>
								<p>The primary purpose of NeuralVisUAL is to further the research in the field of neural network visualizations. DNNs, especially for computer vision, possess a high level of complexity, often having hundreds of millions, or even billions of trainable weights [SZ14, BMR<sup>+</sup>20, SMM<sup>+</sup>17]. This complexity makes it relatively difficult for researchers to comprehensively grasp these networks' precise mechanisms to generate super-human results [ZZ18, ZGCH21]. The fields of neural network interpretability and visualization help answer this question, aiming to give researchers and developers more profound insight into the inner workings of AI [ZZ18].</p>
								<p>NeuralVisUAL currently works exclusively on feed-forward DNNs developed with TensorFlow and Keras, has been tested on a 64-bit Windows computer with the WebSocket connecting through localhost. Due to its adaptability, the provided visualization can be extended, depending on the project-specific requirements of such a visualization. For example, it could be helpful to increase interactivity, implement more user guidance, display individual neurons or show backpropagation. It also could be useful to implement feature visualization [OMS17], training progress comparison, VR visualization, or interactive exploration of latent space [LNH<sup>+</sup>18, STN<sup>+</sup>16] and spatial activations [CAS<sup>+</sup>19].</p>
								<p>NeuralVisUAL is a modular CNN visualization framework that helps researchers obtain a more exhaustive understanding of neural networks. Its settings, modularity, and open-source status make it easily adaptable to personal preferences and extendable to individual visualization requirements. NeuralVisUAL contains helpful features to visualize architecture, kernels, activations, saliency, and gradients and allows users to intuitively comprehend how a CNN processes the input information, furthering research into AI visualization and explainability.</p>
							</details>

						<a target="_blank" href="https://drive.google.com/file/d/1lViMtYSkV5p2BQoxMivBG5NKNootr9Fz/view?usp=sharing" title="View the master thesis as a PDF file" class="no-underline"><p class="italic text-center"><svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6 inline-block" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2">
							<path stroke-linecap="round" stroke-linejoin="round" d="M4 16v1a3 3 0 003 3h10a3 3 0 003-3v-1m-4-4l-4 4m0 0l-4-4m4 4V4" />
						</svg><span class="!no-underline">&ensp;</span><span class="underline">Read more scientific details in the full PDF of this thesis</span></p></a>
						</div>
					</div>
				</div>
			</div>
		</main>
		<div id="footer">
			<noscript><div class="px-5 pb-8 pt-6 bg-orange-100 mainpaddingx border-y-2 border-red-800">
				<span class="font-bold text-red-800">Please enable javascript to show my contact information</span><br /><br />
				Or <a href="/src/footer.html" class="underline">click here to view contact info</a> and come back using your browsers back button.<br /><br />
				Please let me know that this is a problem for you by <a target="_blank" class="underline" id='customemail' 
			href="mailto:webdev@jannikh.com?subject=Please work around the javascript issue&body=Hi%20Jannik%2C%0D%0A%0D%0AI%20m%20rying%20o%20iew%20our%20website%20without%20using%20javascript,%20would%20appreciate%20it%20if%20you%20could%20make%20it%20viewable%20for%20me%20too.%0D%0A%0D%0ACheers"
			title="Notify me of this issue">sending me an e-mail</a>
			</div></noscript>
		</div>
	</div>
</body>
</html>